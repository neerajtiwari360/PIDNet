{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch model to Onnx Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating output\\cityscapes\\pidnet_small_cityscapes_trainval\n",
      "=> creating log\\cityscapes\\pidnet_small\\pidnet_small_cityscapes_trainval_2024-07-01-19-32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from models.pidnet import get_seg_model\n",
    "from configs import config, update_config\n",
    "from utils.utils import create_logger\n",
    "from torch.onnx import TrainingMode\n",
    "\n",
    "def update_config_for_conversion(cfg_file):\n",
    "    \"\"\"Update the configuration for model conversion.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Convert PyTorch model to ONNX')\n",
    "    parser.add_argument('--cfg', help='Experiment configure file name', default=cfg_file, type=str)\n",
    "    parser.add_argument('--onnx-path', help='Path to save the ONNX model', default=\"model.onnx\", type=str)\n",
    "    parser.add_argument('opts', help=\"Modify config options using the command-line\", default=None, nargs=argparse.REMAINDER)\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "    update_config(config, args)\n",
    "    return args\n",
    "\n",
    "def load_model(cfg, model_file):\n",
    "    \"\"\"Load the model from a file.\"\"\"\n",
    "    model = get_seg_model(cfg, imgnet_pretrained=True)\n",
    "    pretrained_dict = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "    \n",
    "    if 'state_dict' in pretrained_dict:\n",
    "        pretrained_dict = pretrained_dict['state_dict']\n",
    "    \n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if k[6:] in model_dict.keys()}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def convert_to_onnx(model, onnx_path, input_size):\n",
    "    \"\"\"Convert the model to ONNX format.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare dummy input\n",
    "    dummy_input = torch.randn(3, 3, input_size[1], input_size[0])\n",
    "    \n",
    "    # Convert model to ONNX format\n",
    "    torch.onnx.export(model, dummy_input, onnx_path,\n",
    "                      export_params=True,\n",
    "                      opset_version=11,\n",
    "                      do_constant_folding=True,\n",
    "                      input_names=['input'],\n",
    "                      output_names=['output'])\n",
    "                    #   training=TrainingMode.TRAINING)\n",
    "    \n",
    "    print(f'Model has been converted to ONNX and saved at {onnx_path}')\n",
    "\n",
    "def main():\n",
    "    # Define paths and configuration file\n",
    "    cfg_file = r\"D:\\github\\PIDNet\\configs\\cityscapes\\pidnet_small_cityscapes_trainval.yaml\"\n",
    "    model_file = r\"D:\\github\\PIDNet\\pretrained_models\\cityscapes\\PIDNet_S_Cityscapes_test.pt\"\n",
    "    #onnx_path = r\"D:\\github\\PIDNet\\pretrained_models\\onnx\\model.onnx\"\n",
    "    onnx_path = r\"D:\\github\\ai2hardware\\tests\\test_c_code\\test2\\onnx2c\\onnx_models\\model.onnx\"\n",
    "    \n",
    "    # Update the configuration\n",
    "    args = update_config_for_conversion(cfg_file)\n",
    "    \n",
    "    # Create logger\n",
    "    logger, final_output_dir, _ = create_logger(config, args.cfg, 'test')\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(config, model_file)\n",
    "    \n",
    "    # Convert to ONNX\n",
    "    convert_to_onnx(model, onnx_path, config.TEST.IMAGE_SIZE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Freezed Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating output\\cityscapes\\pidnet_small_cityscapes_trainval\n",
      "=> creating log\\cityscapes\\pidnet_small\\pidnet_small_cityscapes_trainval_2024-07-01-19-30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Attention!!!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Loaded 302 parameters!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n",
      "Over!!!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has been converted to ONNX and saved at D:\\github\\ai2hardware\\tests\\test_c_code\\test2\\onnx2c\\onnx_models\\model.onnx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "from models.pidnet import get_seg_model\n",
    "from configs import config, update_config\n",
    "from utils.utils import create_logger\n",
    "\n",
    "def update_config_for_conversion(cfg_file):\n",
    "    \"\"\"Update the configuration for model conversion.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Convert PyTorch model to ONNX')\n",
    "    parser.add_argument('--cfg', help='Experiment configure file name', default=cfg_file, type=str)\n",
    "    parser.add_argument('--onnx-path', help='Path to save the ONNX model', default=\"model.onnx\", type=str)\n",
    "    parser.add_argument('opts', help=\"Modify config options using the command-line\", default=None, nargs=argparse.REMAINDER)\n",
    "    \n",
    "    args = parser.parse_args(args=[])\n",
    "    update_config(config, args)\n",
    "    return args\n",
    "\n",
    "def load_model(cfg, model_file):\n",
    "    \"\"\"Load the model from a file.\"\"\"\n",
    "    model = get_seg_model(cfg, imgnet_pretrained=True)\n",
    "    pretrained_dict = torch.load(model_file, map_location=torch.device('cpu'))\n",
    "    \n",
    "    if 'state_dict' in pretrained_dict:\n",
    "        pretrained_dict = pretrained_dict['state_dict']\n",
    "    \n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict = {k[6:]: v for k, v in pretrained_dict.items() if k[6:] in model_dict.keys()}\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def convert_to_onnx(model, onnx_path, input_size):\n",
    "    \"\"\"Convert the model to ONNX format for inference.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Prepare dummy input\n",
    "    dummy_input = torch.randn(3, 3, input_size[1], input_size[0])\n",
    "    \n",
    "    # Convert model to ONNX format for inference\n",
    "    torch.onnx.export(model, dummy_input, onnx_path,\n",
    "                      export_params=True,\n",
    "                      opset_version=11,\n",
    "                      do_constant_folding=True,\n",
    "                      input_names=['input'],\n",
    "                      output_names=['output'])\n",
    "    \n",
    "    print(f'Model has been converted to ONNX and saved at {onnx_path}')\n",
    "\n",
    "def main():\n",
    "    # Define paths and configuration file\n",
    "    cfg_file = r\"D:\\github\\PIDNet\\configs\\cityscapes\\pidnet_small_cityscapes_trainval.yaml\"\n",
    "    model_file = r\"D:\\github\\PIDNet\\pretrained_models\\cityscapes\\PIDNet_S_Cityscapes_test.pt\"\n",
    "    onnx_path = r\"D:\\github\\ai2hardware\\tests\\test_c_code\\test2\\onnx2c\\onnx_models\\model.onnx\"\n",
    "    \n",
    "    # Update the configuration\n",
    "    args = update_config_for_conversion(cfg_file)\n",
    "    \n",
    "    # Create logger\n",
    "    logger, final_output_dir, _ = create_logger(config, args.cfg, 'test')\n",
    "    \n",
    "    # Load the model\n",
    "    model = load_model(config, model_file)\n",
    "    \n",
    "    # Convert to ONNX for inference\n",
    "    convert_to_onnx(model, onnx_path, config.TEST.IMAGE_SIZE)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play With ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
